{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75af35ed-a01a-413c-b336-dea3c08345a3",
   "metadata": {},
   "source": [
    "# IMPORT DATA DAN LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf07e7ac-c1fe-411c-a25b-d983de9e04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# split & CV\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "# base & transformers\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# imbalanced\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# model & metrics \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c78126b-29d4-4816-9343-532c7c93a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DataFrame_processed/DataFrame_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6f0a4d7-ed14-4510-b56b-060783915a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Attrition\"])\n",
    "y = df[\"Attrition\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc883bb-bee5-42b5-8c2d-8749b2f9233a",
   "metadata": {},
   "source": [
    "# PIPELINE FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48202096-8904-44c3-baad-2aa8dbdc9d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline transformasi\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), selector(dtype_include=np.number)),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), selector(dtype_exclude=np.number)),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# full preprocessing pipeline\n",
    "pipe = ImbPipeline(steps=[\n",
    "    (\"prep\", prep),\n",
    "    (\"smote\", SMOTETomek(random_state=42)),\n",
    "    (\"clf\", RandomForestClassifier(n_estimators=400, random_state=42, n_jobs=-1)) # bisa tambah ata ganti model lain \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2109d5ee-84e2-4881-a70b-9881945b5958",
   "metadata": {},
   "source": [
    "> ## Untuk output score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd865eae-1c0b-4787-8ed8-37457f2a95b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST REPORT ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8856    0.9717    0.9266       247\n",
      "           1     0.6957    0.3404    0.4571        47\n",
      "\n",
      "    accuracy                         0.8707       294\n",
      "   macro avg     0.7906    0.6560    0.6919       294\n",
      "weighted avg     0.8552    0.8707    0.8516       294\n",
      "\n",
      "Test ROC-AUC: 0.8154\n"
     ]
    }
   ],
   "source": [
    "# Silakan di copas \n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred  = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "print(\"\\n=== TEST REPORT ===\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(\"Test ROC-AUC:\", roc_auc_score(y_test, y_proba).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7286aea-1665-4aaa-991e-370ff4dc77e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e321b351-d3fe-40f4-bfc3-d2a2e3c8b526",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70474b5c-f68a-4b42-9253-5ea5d94bfac1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8cc8ff-e327-47c3-8b0a-95a6e7cbfa0e",
   "metadata": {},
   "source": [
    "> ## HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b54311-6bbd-4d82-aada-2451a335654b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model 2 - Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4eaead-5b5b-43a6-9bfa-df727153fad4",
   "metadata": {},
   "source": [
    "> ## HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335757fd-efc8-43a7-9dca-90b55088373f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model 3 - Bagging Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6488bb0b-fa8e-453c-9154-a19ccb7b728d",
   "metadata": {},
   "source": [
    "> ## HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfb272e-88ff-4455-9460-9a7ebaf9194f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model 4 - Ada Boost Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c2335d-058c-4f60-8edd-5054cf58e238",
   "metadata": {},
   "source": [
    "> ## HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa7080e-58eb-445e-af16-c6bf5e58d9d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model 5 - Ensemble Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1  : [0.44  0.208 0.448 0.491 0.485] | mean = 0.415\n",
      "CV AUC : [0.777 0.724 0.822 0.867 0.78 ] | mean = 0.794\n",
      "\n",
      "=== TEST REPORT ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8856    0.9717    0.9266       247\n",
      "           1     0.6957    0.3404    0.4571        47\n",
      "\n",
      "    accuracy                         0.8707       294\n",
      "   macro avg     0.7906    0.6560    0.6919       294\n",
      "weighted avg     0.8552    0.8707    0.8516       294\n",
      "\n",
      "Test ROC-AUC: 0.816\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# split & CV\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# base & transformers\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# imbalanced\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# model & metrics \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, average_precision_score, confusion_matrix\n",
    "\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv(\"ibm data.csv\").copy()\n",
    "\n",
    "# map target ke 0/1\n",
    "if df[\"Attrition\"].dtype == object:\n",
    "    df[\"Attrition\"] = df[\"Attrition\"].map({\"No\": 0, \"Yes\": 1}).astype(int)\n",
    "\n",
    "\n",
    "# drop kolom\n",
    "DROP_COLS = [\n",
    "    \"EmployeeCount\",\"StandardHours\",\"Over18\",\"PerformanceRating\",\n",
    "    \"EmployeeNumber\",\"Education\",\"JobLevel\",\"PercentSalaryHike\",\"Gender\",\n",
    "    \"YearsAtCompany\",\"YearsWithCurrManager\",\"NumCompaniesWorked\",\n",
    "    \"YearsSinceLastPromotion\",\"RelationshipSatisfaction\"\n",
    "]\n",
    "\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "\n",
    "\n",
    "# feature engineering\n",
    "def apply_fe(fe):\n",
    "    fe = fe.copy()\n",
    "    if {\"YearsInCurrentRole\",\"TotalWorkingYears\"}.issubset(fe.columns):\n",
    "        denom = fe[\"TotalWorkingYears\"].replace(0, np.nan)\n",
    "        fe[\"ExperienceRatio\"] = (fe[\"YearsInCurrentRole\"] / denom).fillna(0)\n",
    "\n",
    "    if {\"MonthlyIncome\",\"TotalWorkingYears\"}.issubset(fe.columns):\n",
    "        fe[\"IncomePerYearExp\"] = fe[\"MonthlyIncome\"] / (fe[\"TotalWorkingYears\"] + 1)\n",
    "\n",
    "    if {\"YearsInCurrentRole\",\"JobSatisfaction\"}.issubset(fe.columns):\n",
    "        fe[\"TenureSatisfaction\"] = fe[\"YearsInCurrentRole\"] * fe[\"JobSatisfaction\"]\n",
    "    return fe\n",
    "\n",
    "df_fe = apply_fe(df)\n",
    "\n",
    "# split data\n",
    "X = df_fe.drop(columns=[\"Attrition\"])\n",
    "y = df_fe[\"Attrition\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# encoding & scaling/standarisasi\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), selector(dtype_include=np.number)),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), selector(dtype_exclude=np.number)),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipe = ImbPipeline(steps=[\n",
    "    (\"prep\", prep),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"clf\", RandomForestClassifier(n_estimators=400, random_state=42, n_jobs=-1)) # bisa tambah ata ganti model lain \n",
    "])\n",
    "\n",
    "\n",
    "# ngetest doang\n",
    "# cv di train \n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_f1  = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"f1\")\n",
    "cv_auc = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"roc_auc\")\n",
    "print(\"CV F1  :\", np.round(cv_f1, 3),  \"| mean =\", cv_f1.mean().round(3))\n",
    "print(\"CV AUC :\", np.round(cv_auc, 3), \"| mean =\", cv_auc.mean().round(3))\n",
    "\n",
    "# fit di train, predict di test\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred  = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "print(\"\\n=== TEST REPORT ===\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(\"Test ROC-AUC:\", roc_auc_score(y_test, y_proba).round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ca755-6660-4277-8385-4f3330092161",
   "metadata": {},
   "source": [
    "> ## HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3e85a10-2803-4d8b-a236-303ad17d77d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RF] best F1: 0.4696\n",
      "[RF] best params: {'smote__k_neighbors': 5, 'clf__n_estimators': 500, 'clf__min_samples_leaf': 4, 'clf__max_features': 'sqrt', 'clf__max_depth': None}\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "\n",
      "[XGB] best F1: 0.5003\n",
      "[XGB] best params: {'smote__k_neighbors': 5, 'clf__subsample': 1.0, 'clf__n_estimators': 300, 'clf__max_depth': 6, 'clf__learning_rate': 0.1, 'clf__colsample_bytree': 1.0}\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 20 is smaller than n_iter=30. Running 20 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LR] best F1: 0.4940\n",
      "[LR] best params: {'smote__k_neighbors': 5, 'clf__class_weight': None, 'clf__C': 5.0}\n",
      "\n",
      "=== RF (thr=0.5) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8902    0.9514    0.9198       247\n",
      "           1     0.6000    0.3830    0.4675        47\n",
      "\n",
      "    accuracy                         0.8605       294\n",
      "   macro avg     0.7451    0.6672    0.6936       294\n",
      "weighted avg     0.8438    0.8605    0.8475       294\n",
      "\n",
      "ROC-AUC: 0.8174\n",
      "\n",
      "=== XGB (thr=0.5) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8778    0.9595    0.9168       247\n",
      "           1     0.5833    0.2979    0.3944        47\n",
      "\n",
      "    accuracy                         0.8537       294\n",
      "   macro avg     0.7306    0.6287    0.6556       294\n",
      "weighted avg     0.8307    0.8537    0.8333       294\n",
      "\n",
      "ROC-AUC: 0.7795\n",
      "\n",
      "=== LR (thr=0.5) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9303    0.7571    0.8348       247\n",
      "           1     0.3548    0.7021    0.4714        47\n",
      "\n",
      "    accuracy                         0.7483       294\n",
      "   macro avg     0.6426    0.7296    0.6531       294\n",
      "weighted avg     0.8383    0.7483    0.7767       294\n",
      "\n",
      "ROC-AUC: 0.7914\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def tune(pipe, param_dist, name, n_iter=30):\n",
    "    rsearch = RandomizedSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter, scoring=\"f1\",\n",
    "        cv=cv, n_jobs=-1, verbose=1, random_state=42\n",
    "    )\n",
    "    rsearch.fit(X_train, y_train)\n",
    "    print(f\"\\n[{name}] best F1: {rsearch.best_score_:.4f}\")\n",
    "    print(f\"[{name}] best params: {rsearch.best_params_}\")\n",
    "    return rsearch.best_estimator_\n",
    "\n",
    "# ========== 1) RF PIPE ==========\n",
    "rf_pipe = ImbPipeline(steps=[\n",
    "    (\"prep\", prep),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"clf\", RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "])\n",
    "rf_dist = {\n",
    "    \"clf__n_estimators\": [300, 500, 800],\n",
    "    \"clf__max_depth\": [None, 10, 20],\n",
    "    \"clf__min_samples_leaf\": [1, 2, 4],\n",
    "    \"clf__max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"smote__k_neighbors\": [3, 5]\n",
    "}\n",
    "rf_best = tune(rf_pipe, rf_dist, \"RF\")\n",
    "\n",
    "# ========== 2) XGB PIPE ==========\n",
    "xgb_pipe = ImbPipeline(steps=[\n",
    "    (\"prep\", prep),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"clf\", XGBClassifier(\n",
    "        eval_metric=\"logloss\", tree_method=\"hist\",\n",
    "        random_state=42, n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "xgb_dist = {\n",
    "    \"clf__n_estimators\": [300, 500, 800],\n",
    "    \"clf__learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"clf__max_depth\": [4, 6, 8],\n",
    "    \"clf__subsample\": [0.8, 1.0],\n",
    "    \"clf__colsample_bytree\": [0.8, 1.0],\n",
    "    \"smote__k_neighbors\": [3, 5]\n",
    "}\n",
    "xgb_best = tune(xgb_pipe, xgb_dist, \"XGB\")\n",
    "\n",
    "# ========== 3) LR PIPE ==========\n",
    "lr_pipe = ImbPipeline(steps=[\n",
    "    (\"prep\", prep),  # scaling penting buat LR\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "])\n",
    "lr_dist = {\n",
    "    \"clf__C\": [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "    \"clf__class_weight\": [None, \"balanced\"],\n",
    "    \"smote__k_neighbors\": [3, 5]\n",
    "}\n",
    "lr_best = tune(lr_pipe, lr_dist, \"LR\")\n",
    "\n",
    "# ========== 4) EVAL CEPAT per model ==========\n",
    "def quick_test(name, best_pipe):\n",
    "    best_pipe.fit(X_train, y_train)\n",
    "    proba = best_pipe.predict_proba(X_test)[:,1]\n",
    "    y_pred = (proba >= 0.5).astype(int)  # optional: nanti bisa threshold tuning\n",
    "    print(f\"\\n=== {name} (thr=0.5) ===\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_test, proba).round(4))\n",
    "\n",
    "quick_test(\"RF\", rf_best)\n",
    "quick_test(\"XGB\", xgb_best)\n",
    "quick_test(\"LR\",  lr_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STACK (no tuning) | CV F1 : [0.542 0.407 0.585 0.618 0.521] | mean = 0.534\n",
      "STACK (no tuning) | CV AUC: [0.825 0.76  0.841 0.878 0.804] | mean = 0.821\n",
      "\n",
      "=== STACK (no tuning) — TEST ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8859    0.9433    0.9137       247\n",
      "           1     0.5484    0.3617    0.4359        47\n",
      "\n",
      "    accuracy                         0.8503       294\n",
      "   macro avg     0.7172    0.6525    0.6748       294\n",
      "weighted avg     0.8320    0.8503    0.8373       294\n",
      "\n",
      "Test ROC-AUC: 0.7922\n"
     ]
    }
   ],
   "source": [
    "# ambil model inti (tanpa prep/smote) dari best pipes\n",
    "rf_clf  = rf_best.named_steps[\"clf\"]\n",
    "xgb_clf = xgb_best.named_steps[\"clf\"]\n",
    "lr_clf  = lr_best.named_steps[\"clf\"]\n",
    "\n",
    "# definisi stacking (meta-learner = LR)\n",
    "stack_clf = StackingClassifier(\n",
    "    estimators=[(\"rf\", rf_clf), (\"xgb\", xgb_clf), (\"lr\", lr_clf)],\n",
    "    final_estimator=LogisticRegression(max_iter=2000),\n",
    "    stack_method=\"predict_proba\",\n",
    "    passthrough=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# pipeline stacking lengkap (prep → SMOTE → stacking)\n",
    "stack_pipe = ImbPipeline(steps=[\n",
    "    (\"prep\", prep),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"clf\", stack_clf),\n",
    "])\n",
    "\n",
    "# --- evaluasi CV di TRAIN (cepat) ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_f1  = cross_val_score(stack_pipe, X_train, y_train, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "cv_auc = cross_val_score(stack_pipe, X_train, y_train, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "print(\"STACK (no tuning) | CV F1 :\", np.round(cv_f1, 3),  \"| mean =\", cv_f1.mean().round(3))\n",
    "print(\"STACK (no tuning) | CV AUC:\", np.round(cv_auc, 3), \"| mean =\", cv_auc.mean().round(3))\n",
    "\n",
    "# --- fit & test ---\n",
    "stack_pipe.fit(X_train, y_train)\n",
    "proba_test = stack_pipe.predict_proba(X_test)[:, 1]\n",
    "y_pred     = (proba_test >= 0.5).astype(int)   # threshold default 0.5\n",
    "print(\"\\n=== STACK (no tuning) — TEST ===\")\n",
    "print(classification_report(y_test, y_pred, digits=4))print(\"Test ROC-AUC:\", roc_auc_score(y_test, proba_test).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "\n",
      "[STACK] Best params: {'smote__k_neighbors': 5, 'clf__xgb__subsample': 0.8, 'clf__xgb__n_estimators': 300, 'clf__xgb__max_depth': 6, 'clf__xgb__learning_rate': 0.05, 'clf__xgb__colsample_bytree': 1.0, 'clf__rf__n_estimators': 300, 'clf__rf__min_samples_leaf': 2, 'clf__rf__max_features': 'sqrt', 'clf__rf__max_depth': None, 'clf__final_estimator__C': 0.5}\n",
      "[STACK] Best CV F1 : 0.5362\n",
      "\n",
      "=== STACK (tuned; thr=0.5) — TEST ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8893    0.9433    0.9155       247\n",
      "           1     0.5625    0.3830    0.4557        47\n",
      "\n",
      "    accuracy                         0.8537       294\n",
      "   macro avg     0.7259    0.6631    0.6856       294\n",
      "weighted avg     0.8371    0.8537    0.8420       294\n",
      "\n",
      "Test ROC-AUC: 0.7974\n"
     ]
    }
   ],
   "source": [
    "# param dist untuk tuning ringan \n",
    "stack_dist = {\n",
    "    # meta-learner (LogReg)\n",
    "    \"clf__final_estimator__C\": [0.5, 1.0, 2.0, 5.0],\n",
    "    # base RF\n",
    "    \"clf__rf__n_estimators\": [300, 500, 800],\n",
    "    \"clf__rf__max_depth\": [None, 10, 20],\n",
    "    \"clf__rf__min_samples_leaf\": [1, 2, 4],\n",
    "    \"clf__rf__max_features\": [\"sqrt\", \"log2\"],\n",
    "    # base XGB\n",
    "    \"clf__xgb__n_estimators\": [300, 500, 800],\n",
    "    \"clf__xgb__learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"clf__xgb__max_depth\": [4, 6, 8],\n",
    "    \"clf__xgb__subsample\": [0.8, 1.0],\n",
    "    \"clf__xgb__colsample_bytree\": [0.8, 1.0],\n",
    "    # SMOTE\n",
    "    \"smote__k_neighbors\": [3, 5]\n",
    "}\n",
    "\n",
    "rsearch_stack = RandomizedSearchCV(\n",
    "    estimator=stack_pipe,\n",
    "    param_distributions=stack_dist,\n",
    "    n_iter=40,                    # naikin kalau mau explore lebih luas\n",
    "    scoring=\"f1\",                 # bisa ganti ke F2 kalau fokus recall\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rsearch_stack.fit(X_train, y_train)\n",
    "print(\"\\n[STACK] Best params:\", rsearch_stack.best_params_)\n",
    "print(\"[STACK] Best CV F1 :\", round(rsearch_stack.best_score_, 4))\n",
    "\n",
    "stack_best = rsearch_stack.best_estimator_\n",
    "\n",
    "# --- evaluasi di test dengan threshold default 0.5 ---\n",
    "stack_best.fit(X_train, y_train)\n",
    "proba_test = stack_best.predict_proba(X_test)[:, 1]\n",
    "y_pred     = (proba_test >= 0.5).astype(int)\n",
    "print(\"\\n=== STACK (tuned; thr=0.5) — TEST ===\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(\"Test ROC-AUC:\", roc_auc_score(y_test, proba_test).round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
