{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75af35ed-a01a-413c-b336-dea3c08345a3",
   "metadata": {},
   "source": [
    "# IMPORT DATA DAN LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf07e7ac-c1fe-411c-a25b-d983de9e04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# split & CV\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "# base & transformers\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# imbalanced\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# model & metrics \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c78126b-29d4-4816-9343-532c7c93a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DataFrame_processed/DataFrame_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6f0a4d7-ed14-4510-b56b-060783915a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Attrition\"])\n",
    "y = df[\"Attrition\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc883bb-bee5-42b5-8c2d-8749b2f9233a",
   "metadata": {},
   "source": [
    "# PIPELINE FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48202096-8904-44c3-baad-2aa8dbdc9d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline transformasi\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), selector(dtype_include=np.number)),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), selector(dtype_exclude=np.number)),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# full preprocessing pipeline\n",
    "pipe = ImbPipeline(steps=[\n",
    "    (\"prep\", prep),\n",
    "    (\"smote\", SMOTETomek(random_state=42)),\n",
    "    (\"clf\", RandomForestClassifier(n_estimators=400, random_state=42, n_jobs=-1)) # bisa tambah ata ganti model lain \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2109d5ee-84e2-4881-a70b-9881945b5958",
   "metadata": {},
   "source": [
    "> ## Untuk output score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd865eae-1c0b-4787-8ed8-37457f2a95b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST REPORT ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8856    0.9717    0.9266       247\n",
      "           1     0.6957    0.3404    0.4571        47\n",
      "\n",
      "    accuracy                         0.8707       294\n",
      "   macro avg     0.7906    0.6560    0.6919       294\n",
      "weighted avg     0.8552    0.8707    0.8516       294\n",
      "\n",
      "Test ROC-AUC: 0.8154\n"
     ]
    }
   ],
   "source": [
    "# Silakan di copas \n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred  = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "print(\"\\n=== TEST REPORT ===\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(\"Test ROC-AUC:\", roc_auc_score(y_test, y_proba).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7286aea-1665-4aaa-991e-370ff4dc77e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e321b351-d3fe-40f4-bfc3-d2a2e3c8b526",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70474b5c-f68a-4b42-9253-5ea5d94bfac1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8cc8ff-e327-47c3-8b0a-95a6e7cbfa0e",
   "metadata": {},
   "source": [
    "> ## HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b54311-6bbd-4d82-aada-2451a335654b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model 2 - Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4eaead-5b5b-43a6-9bfa-df727153fad4",
   "metadata": {},
   "source": [
    "> ## HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335757fd-efc8-43a7-9dca-90b55088373f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model 3 - Bagging Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6488bb0b-fa8e-453c-9154-a19ccb7b728d",
   "metadata": {},
   "source": [
    "> ## HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfb272e-88ff-4455-9460-9a7ebaf9194f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model 4 - Ada Boost Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c2335d-058c-4f60-8edd-5054cf58e238",
   "metadata": {},
   "source": [
    "> ## HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa7080e-58eb-445e-af16-c6bf5e58d9d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model 5 - Ensemble Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1  : [0.44  0.208 0.448 0.491 0.485] | mean = 0.415\n",
      "CV AUC : [0.777 0.724 0.822 0.867 0.78 ] | mean = 0.794\n",
      "\n",
      "=== TEST REPORT ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8856    0.9717    0.9266       247\n",
      "           1     0.6957    0.3404    0.4571        47\n",
      "\n",
      "    accuracy                         0.8707       294\n",
      "   macro avg     0.7906    0.6560    0.6919       294\n",
      "weighted avg     0.8552    0.8707    0.8516       294\n",
      "\n",
      "Test ROC-AUC: 0.816\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# split & CV\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "\n",
    "# base & transformers\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# imbalanced\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# model & metrics \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, average_precision_score, confusion_matrix\n",
    "\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv(\"ibm data.csv\").copy()\n",
    "\n",
    "# map target ke 0/1\n",
    "if df[\"Attrition\"].dtype == object:\n",
    "    df[\"Attrition\"] = df[\"Attrition\"].map({\"No\": 0, \"Yes\": 1}).astype(int)\n",
    "\n",
    "\n",
    "# drop kolom\n",
    "DROP_COLS = [\n",
    "    \"EmployeeCount\",\"StandardHours\",\"Over18\",\"PerformanceRating\",\n",
    "    \"EmployeeNumber\",\"Education\",\"JobLevel\",\"PercentSalaryHike\",\"Gender\",\n",
    "    \"YearsAtCompany\",\"YearsWithCurrManager\",\"NumCompaniesWorked\",\n",
    "    \"YearsSinceLastPromotion\",\"RelationshipSatisfaction\"\n",
    "]\n",
    "\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "\n",
    "\n",
    "# feature engineering\n",
    "def apply_fe(fe):\n",
    "    fe = fe.copy()\n",
    "    if {\"YearsInCurrentRole\",\"TotalWorkingYears\"}.issubset(fe.columns):\n",
    "        denom = fe[\"TotalWorkingYears\"].replace(0, np.nan)\n",
    "        fe[\"ExperienceRatio\"] = (fe[\"YearsInCurrentRole\"] / denom).fillna(0)\n",
    "\n",
    "    if {\"MonthlyIncome\",\"TotalWorkingYears\"}.issubset(fe.columns):\n",
    "        fe[\"IncomePerYearExp\"] = fe[\"MonthlyIncome\"] / (fe[\"TotalWorkingYears\"] + 1)\n",
    "\n",
    "    if {\"YearsInCurrentRole\",\"JobSatisfaction\"}.issubset(fe.columns):\n",
    "        fe[\"TenureSatisfaction\"] = fe[\"YearsInCurrentRole\"] * fe[\"JobSatisfaction\"]\n",
    "    return fe\n",
    "\n",
    "df_fe = apply_fe(df)\n",
    "\n",
    "# split data\n",
    "X = df_fe.drop(columns=[\"Attrition\"])\n",
    "y = df_fe[\"Attrition\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# encoding & scaling/standarisasi\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), selector(dtype_include=np.number)),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), selector(dtype_exclude=np.number)),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipe = ImbPipeline(steps=[\n",
    "    (\"prep\", prep),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"clf\", RandomForestClassifier(n_estimators=400, random_state=42, n_jobs=-1)) # bisa tambah ata ganti model lain \n",
    "])\n",
    "\n",
    "\n",
    "# ngetest doang\n",
    "# cv di train \n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_f1  = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"f1\")\n",
    "cv_auc = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"roc_auc\")\n",
    "print(\"CV F1  :\", np.round(cv_f1, 3),  \"| mean =\", cv_f1.mean().round(3))\n",
    "print(\"CV AUC :\", np.round(cv_auc, 3), \"| mean =\", cv_auc.mean().round(3))\n",
    "\n",
    "# fit di train, predict di test\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred  = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "print(\"\\n=== TEST REPORT ===\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(\"Test ROC-AUC:\", roc_auc_score(y_test, y_proba).round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ca755-6660-4277-8385-4f3330092161",
   "metadata": {},
   "source": [
    "> ## HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e85a10-2803-4d8b-a236-303ad17d77d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1  : [0.44  0.208 0.448 0.491 0.485] | mean = 0.415\n",
      "CV AUC : [0.777 0.724 0.822 0.867 0.78 ] | mean = 0.794\n",
      "Fitting 5 folds for each of 6912 candidates, totalling 34560 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'final_estimator' for estimator RandomForestClassifier(n_estimators=400, n_jobs=-1, random_state=42). Valid parameters are: ['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'monotonic_cst', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 490, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py\", line 607, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py\", line 607, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 854, in _fit_and_score\n    estimator = estimator.set_params(**clone(parameters, safe=False))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/pipeline.py\", line 320, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/metaestimators.py\", line 69, in _set_params\n    super().set_params(**params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 295, in set_params\n    valid_params[key].set_params(**sub_params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 283, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'final_estimator' for estimator RandomForestClassifier(n_estimators=400, n_jobs=-1, random_state=42). Valid parameters are: ['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'monotonic_cst', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 67\u001b[39m\n\u001b[32m     41\u001b[39m param_grid = {\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# RF (base)\u001b[39;00m\n\u001b[32m     43\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mclf__rf__n_estimators\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m300\u001b[39m, \u001b[32m500\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msmote__k_neighbors\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m3\u001b[39m, \u001b[32m5\u001b[39m]\n\u001b[32m     57\u001b[39m }\n\u001b[32m     59\u001b[39m gs = GridSearchCV(\n\u001b[32m     60\u001b[39m     estimator=pipe,\n\u001b[32m     61\u001b[39m     param_grid=param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     66\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[43mgs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBest params:\u001b[39m\u001b[33m\"\u001b[39m, gs.best_params_)\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest CV F1 :\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mround\u001b[39m(gs.best_score_, \u001b[32m4\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1571\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1784\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1782\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1783\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1785\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1787\u001b[39m     nb_jobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1859\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1855\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1856\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1857\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:758\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    752\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:773\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Invalid parameter 'final_estimator' for estimator RandomForestClassifier(n_estimators=400, n_jobs=-1, random_state=42). Valid parameters are: ['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'monotonic_cst', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start']."
     ]
    }
   ],
   "source": [
    "def best_threshold_by_fbeta(proba, y_true, beta=1.0):\n",
    "    p, r, th = precision_recall_curve(y_true, proba)\n",
    "    if len(th) == 0:\n",
    "        return 0.5\n",
    "    beta2 = beta**2\n",
    "    fbeta = (1+beta2) * (p*r) / (beta2*p + r + 1e-12)   \n",
    "    idx = np.nanargmax(fbeta)\n",
    "    return th[min(idx, len(th)-1)]\n",
    "\n",
    "def evaluate_with_threshold(name, pipe, X_tr, y_tr, X_val, y_val, X_te, y_te, beta=1.0):\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "\n",
    "    # pilih threshold di validation (bukan test)\n",
    "    proba_val = pipe.predict_proba(X_val)[:,1]\n",
    "    thr = best_threshold_by_fbeta(proba_val, y_val, beta=beta)\n",
    "\n",
    "    # final test\n",
    "    proba_te = pipe.predict_proba(X_te)[:,1]\n",
    "    y_pred = (proba_te >= thr).astype(int)\n",
    "\n",
    "    print(f\"\\n=== {name} (thr={thr:.3f}, beta={beta}) ===\")\n",
    "    print(classification_report(y_te, y_pred, digits=4))\n",
    "    roc = roc_auc_score(y_te, proba_te)\n",
    "    ap  = average_precision_score(y_te, proba_te)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_te, y_pred).ravel()\n",
    "    print(f\"ROC-AUC: {roc:.4f} | PR-AUC: {ap:.4f} | CM: tn={tn}, fp={fp}, fn={fn}, tp={tp}\")\n",
    "    return thr, proba_te\n",
    "\n",
    "# ======================\n",
    "# CV baseline (optional quick check)\n",
    "# ======================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_f1  = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"f1\")\n",
    "cv_auc = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"roc_auc\")\n",
    "print(\"CV F1  :\", np.round(cv_f1, 3),  \"| mean =\", cv_f1.mean().round(3))\n",
    "print(\"CV AUC :\", np.round(cv_auc, 3), \"| mean =\", cv_auc.mean().round(3))\n",
    "\n",
    "# ======================\n",
    "# GridSearchCV untuk Stacking (tuning RF, XGB, meta-LR, SMOTE)\n",
    "# ======================\n",
    "param_grid = {\n",
    "    # RF (base)\n",
    "    \"clf__rf__n_estimators\": [300, 500],\n",
    "    \"clf__rf__max_depth\": [None, 10, 20],\n",
    "    \"clf__rf__min_samples_leaf\": [1, 2],\n",
    "    \"clf__rf__max_features\": [\"sqrt\", \"log2\"],\n",
    "    # XGB (base)\n",
    "    \"clf__xgb__n_estimators\": [300, 500],\n",
    "    \"clf__xgb__learning_rate\": [0.05, 0.1],\n",
    "    \"clf__xgb__max_depth\": [4, 6, 8],\n",
    "    \"clf__xgb__subsample\": [0.8, 1.0],\n",
    "    \"clf__xgb__colsample_bytree\": [0.8, 1.0],\n",
    "    # Meta-learner (LR)\n",
    "    \"clf__final_estimator__C\": [0.5, 1.0, 2.0],\n",
    "    # SMOTE\n",
    "    \"smote__k_neighbors\": [3, 5]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1\",          # bisa ganti ke make_scorer(fbeta_score, beta=2) kalau mau recall-heavy\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"\\nBest params:\", gs.best_params_)\n",
    "print(\"Best CV F1 :\", round(gs.best_score_, 4))\n",
    "\n",
    "best_pipe = gs.best_estimator_\n",
    "\n",
    "# ======================\n",
    "# Threshold tuning di validation split, lalu final test\n",
    "# ======================\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    ")\n",
    "thr, _ = evaluate_with_threshold(\n",
    "    name=\"STACK (tuned)\",\n",
    "    pipe=best_pipe,\n",
    "    X_tr=X_tr, y_tr=y_tr,\n",
    "    X_val=X_val, y_val=y_val,\n",
    "    X_te=X_test, y_te=y_test,\n",
    "    beta=1.0   # set 2.0 kalau pengen lebih menekan recall\n",
    ")\n",
    "\n",
    "# ======================\n",
    "# (Optional) bandingin juga default threshold 0.5 langsung di test\n",
    "# ======================\n",
    "best_pipe.fit(X_train, y_train)\n",
    "proba_test = best_pipe.predict_proba(X_test)[:,1]\n",
    "y_pred_05  = (proba_test >= 0.5).astype(int)\n",
    "print(\"\\n=== STACK (tuned, default thr=0.5) ===\")\n",
    "print(classification_report(y_test, y_pred_05, digits=4))\n",
    "print(\"Test ROC-AUC:\", roc_auc_score(y_test, proba_test).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
